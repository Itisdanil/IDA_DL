{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmsFABwClrsS"
   },
   "source": [
    "# Домашняя работа\n",
    "\n",
    "В этой работе вам предстоит с помощью encoder-decoder архитектуры, пробуя различные ее реализации, решить задачу машинного перевода.\n",
    "\n",
    "#### Наша задача - сделать свой собственный переводчик!\n",
    "\n",
    "Пока что только русско-английский:) Будем учиться на текстах описания отелей, так что при успешном выполнении этого задания у вас не возникнет проблем с выбором места для остановки в путешествии, так как все отзывы вам будут высококлассно переведены!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJNm7xw5PnYM"
   },
   "source": [
    "Что необходимо обсудить до начала работы?\n",
    " \n",
    "*как токенезовать и закодировать текст?*\n",
    "\n",
    "С токенезацией хорошо справится WordPunctTokenizer из библиотеки nltk, а вот с кодированием не все так просто, как может показаться... \n",
    "\n",
    "В наших текстах очень много редких и очень мало встречаемых слов (в каждом отеле есть своя фишка: какой-то предмет декорации или услуга, которая описывается своим словом, которое только там и встречается). Если мы будем кодировать все слова, то размер нашего словаря будет очень-очень большим.\n",
    "\n",
    "Но на одном из семинаров мы кодировали побуквенно, кажется, что тут это может помочь! Да, действительно так, но придется очень очень долго обучать модель, а путешествовать и выбрать хороший отель уже хочется, поэтому мы придем к чему-то среднему между этими подходами -  [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt) известный как __BPE__\n",
    "\n",
    "Этот алгоритм стартует с посимвольного уровня и итеративно мерджит самые встречаемые пары. И так N итераций. На выходе мы получаем самые частые последовательности символов из которых формируются слова!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpQpvE2hPnYM"
   },
   "source": [
    "BPE - очень популярный и частоиспользуемый алгоритм в задачах NLP, поэтому есть много открытых реализаций этого алгоритма\n",
    "\n",
    "Мы уверены, что вы научились гуглить и искать полезные материалы в интернете, когда делали домашнее задание по YOLO, поэтому в этот раз просто покажем один из способов, как это можно сделать и затем в своих проектах вы можете брать этот подход и, возможно, как-то улучшать его!\n",
    "\n",
    "Тем кому очень интересно, как же все работает - заходите в файл vocab.py, очень советуем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5hFJyx2qg5g"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wa3sZtm1RFrs"
   },
   "outputs": [],
   "source": [
    "!pip install subword_nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9kP0SdxlrsY",
    "outputId": "6c4f80ca-f924-4f1b-f1fb-227ceec803fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:19<00:00, 420.05it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 723.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "# разбиваем и токенизируем тексты, записываем обработанные токены в файл\n",
    "with open('train.en', 'w') as f_src,  open('train.ru', 'w') as f_dst:\n",
    "    for line in open('/content/drive/MyDrive/data.txt'):\n",
    "        src_line, dst_line = line.strip().split('\\t')\n",
    "        f_src.write(tokenize(src_line) + '\\n')\n",
    "        f_dst.write(tokenize(dst_line) + '\\n')\n",
    "\n",
    "# строим и применяем bpe кодирование\n",
    "bpe = {}\n",
    "for lang in ['en', 'ru']:\n",
    "    learn_bpe(open('./train.' + lang), open('bpe_rules.' + lang, 'w'), num_symbols=8000)\n",
    "    bpe[lang] = BPE(open('./bpe_rules.' + lang))\n",
    "    \n",
    "    with open('train.bpe.' + lang, 'w') as f_out:\n",
    "        for line in open('train.' + lang):\n",
    "            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMSIhUsKPnYO"
   },
   "source": [
    "### Построение словарей, разбиение данных\n",
    "\n",
    "Сейчас, когда мы обучили BPE алгоритм на наших данных, построим словарь соответствия токена и его индекса, чтобы нам было затем удобно смотреть переводы и переводить новые предложения\n",
    "\n",
    "Также сделаем разбиение на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CmTy_m_olrsb"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PskgBSxlrsd",
    "outputId": "26e2f7f9-7b86-41f1-ce54-9828af6d4843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: на территории обустроена бесплатная частная парковка .\n",
      "out: free private parking is available on site .\n",
      "\n",
      "inp: кроме того , в 5 минутах ходьбы работают многочисленные бары и рестораны .\n",
      "out: guests can find many bars and restaurants within a 5 - minute walk .\n",
      "\n",
      "inp: отель san mi@@ gu@@ el расположен в центре мор@@ ели@@ и , в 750 метрах от главной площади города и кафедрального собора .\n",
      "out: hotel san miguel is located in central more@@ lia , 750 metres from the city ’ s main square and cathedral .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_inp = np.array(open('./train.bpe.ru').read().split('\\n'))\n",
    "data_out = np.array(open('./train.bpe.en').read().split('\\n'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n",
    "                                                          random_state=42)\n",
    "for i in range(3):\n",
    "    print('inp:', train_inp[i])\n",
    "    print('out:', train_out[i], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vipg4O61lrsg"
   },
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "inp_voc = Vocab.from_lines(train_inp)\n",
    "out_voc = Vocab.from_lines(train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwOoHfuhlrsi",
    "outputId": "66652a9c-9ab9-4564-8ebe-1664600fce9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "tensor([[   0, 2688, 2943, 1108,   29,    1,    1,    1],\n",
      "        [   0, 2922, 1834, 8035,   59, 3800,   29,    1],\n",
      "        [   0, 6030, 2083,   29,    1,    1,    1,    1],\n",
      "        [   0, 4927, 1870,   29,    1,    1,    1,    1],\n",
      "        [   0, 5549, 1453,   27,  592,   29,    1,    1]])\n",
      "\n",
      "back to words\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n"
     ]
    }
   ],
   "source": [
    "# тут можно посмотреть, как работает мапинг из индекса в токен и наоборот\n",
    "batch_lines = sorted(train_inp, key=len)[5:10]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATLcowUUPnYP"
   },
   "source": [
    "## За вас сделали домашнюю работу? Нет, вам самое интересное!\n",
    "\n",
    "Если вы пролистываете ноутбук и вам уже очень хочется начать писать самим - то мы вас понимаем, задание очень интересное и полезное! \n",
    "И спешим вас обрадовать, так как вы дождались и тут как раз можно проявить всю фантазию и мастерство написание нейронных сетей!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wp0HU9L8PnYP"
   },
   "source": [
    "###  Задание 1 (1 балла)\n",
    "В коде ниже мы представили шаблон простой encoder-decoder модели, без всяких наворотов с Attention или чем-нибудь еще. Вы можете редактировать его под себя: добавлять новые методы, новые переменные, писать на pytorch ligtning и другое.\n",
    "\n",
    "Главное - сохраните идею шаблона и сделайте его очень удобным, так как с ним еще предстоит работать!\n",
    "\n",
    "Заполните пропуски с `<YOUR CODE HERE>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pd_rDRm9lrso"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wRHVv0TK6PZq"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i_xf1idH6Pyb"
   },
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wgfN5-F7lrst"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, inp_voc, out_voc, emb_size=64, hid_size=128):\n",
    "        \"\"\"\n",
    "        Базовая модель encoder-decoder архитектуры\n",
    "        \"\"\"\n",
    "        super().__init__() \n",
    "\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size\n",
    "        \n",
    "        self.emb_inp = nn.Embedding(len(inp_voc), emb_size)\n",
    "        self.emb_out = nn.Embedding(len(out_voc), emb_size)\n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size, hid_size)\n",
    "        self.logits = nn.Linear(hid_size, len(out_voc))\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        \"\"\" Сначала примените  encode а затем decode\"\"\"\n",
    "        initial_state = self.encode(inp)\n",
    "        \n",
    "        return self.decode(initial_state, out)\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Считаем скрытое состояние, которое будет начальным для decode\n",
    "        :param inp: матрица входных токенов\n",
    "        :returns: скрытое представление с которого будет начинаться decode\n",
    "        \"\"\"\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "        \n",
    "        enc_seq, [last_state_but_not_really] = self.enc0(inp_emb)\n",
    "        # enc_seq: [batch, time, hid_size], last_state: [batch, hid_size]\n",
    "        \n",
    "        # последний токен, не последний на самом деле, так как мы делали pading, чтобы тексты были\n",
    "        # одинакового размер, поэтому подсчитать длину исходного предложения не так уж тривиально\n",
    "        lengths = (inp != self.inp_voc.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        # ^-- shape: [batch_size, hid_size]\n",
    "        \n",
    "        dec_start = self.dec_start(last_state)\n",
    "\n",
    "        return [dec_start]\n",
    "\n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Принимает предыдущее состояние декодера и токены, возвращает новое состояние и \n",
    "        логиты для следующих токенов\n",
    "        \"\"\"\n",
    "        prev_gru0_state = prev_state[0]\n",
    "        prev_gru0_tokens = prev_tokens\n",
    "        \n",
    "        x = self.emb_out(prev_gru0_tokens)\n",
    "        new_dec_state = self.dec0(x, prev_state[0])\n",
    "\n",
    "        output_logits = self.logits(new_dec_state)\n",
    "        \n",
    "        return [new_dec_state], output_logits\n",
    "\n",
    "    def decode(self, initial_state, out_tokens, **flags):\n",
    "        batch_size = out_tokens.shape[0]\n",
    "        state = initial_state\n",
    "        \n",
    "        # первый символ всегда BOS\n",
    "        onehot_bos = F.one_hot(torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64),\n",
    "                               num_classes=len(self.out_voc)).to(device=out_tokens.device)\n",
    "        first_logits = torch.log(onehot_bos.to(torch.float32) + 1e-9)\n",
    "        \n",
    "        logits_sequence = [first_logits]\n",
    "        # в цикле делаем decode_step, получаем logits_sequence\n",
    "        for i in range(out_tokens.shape[1] - 1):\n",
    "            state, logits = self.decode_step(state, out_tokens[:, i])\n",
    "            logits_sequence.append(logits)\n",
    "\n",
    "        return torch.stack(logits_sequence, dim=1)\n",
    "\n",
    "    def decode_inference(self, initial_state, max_len=100, **flags):\n",
    "        \"\"\" Генерим токены для перевода \"\"\"\n",
    "        batch_size, device = len(initial_state[0]), initial_state[0].device\n",
    "        state = initial_state\n",
    "        outputs = [torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64, device=device)]\n",
    "        all_states = [initial_state]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            state, logits = self.decode_step(state, outputs[-1])\n",
    "            outputs.append(logits.argmax(dim=-1))\n",
    "            all_states.append(state)\n",
    "        \n",
    "        return torch.stack(outputs, dim=1), all_states\n",
    "\n",
    "    def translate_lines(self, inp_lines, **kwargs):\n",
    "        \"\"\"Функция для перевода\"\"\"\n",
    "        inp = self.inp_voc.to_matrix(inp_lines).to(device)\n",
    "        initial_state = self.encode(inp)\n",
    "        out_ids, states = self.decode_inference(initial_state, **kwargs)\n",
    "\n",
    "        return self.out_voc.to_lines(out_ids.cpu().numpy()), states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2Q1iwqdMPnYQ"
   },
   "outputs": [],
   "source": [
    "# debugging area\n",
    "model = BaseModel(inp_voc, out_voc).to(device)\n",
    "\n",
    "dummy_inp_tokens = inp_voc.to_matrix(sorted(train_inp, key=len)[5:10]).to(device)\n",
    "dummy_out_tokens = out_voc.to_matrix(sorted(train_out, key=len)[5:10]).to(device)\n",
    "\n",
    "h0 = model.encode(dummy_inp_tokens)\n",
    "h1, logits1 = model.decode_step(h0, torch.arange(len(dummy_inp_tokens), device=device))\n",
    "\n",
    "assert isinstance(h1, list) and len(h1) == len(h0)\n",
    "assert h1[0].shape == h0[0].shape and not torch.allclose(h1[0], h0[0])\n",
    "assert logits1.shape == (len(dummy_inp_tokens), len(out_voc))\n",
    "\n",
    "logits_seq = model.decode(h0, dummy_out_tokens)\n",
    "assert logits_seq.shape == (dummy_out_tokens.shape[0], dummy_out_tokens.shape[1], len(out_voc))\n",
    "\n",
    "# full forward\n",
    "logits_seq2 = model(dummy_inp_tokens, dummy_out_tokens)\n",
    "assert logits_seq2.shape == logits_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFfUDko_PnYQ",
    "outputId": "f6091bdf-38dd-4004-c5b3-b85c66db050d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations without training:\n",
      "third asts section bremen reland kastrup above posed posed alexand@@ bakery arg@@ itality freedom bri@@ beijing newspaper stainless collection pensiunea trevi trevi lig@@ pur@@ seaside\n",
      "third asts section bremen reland kastrup above posed posed alexand@@ bakery arg@@ itality freedom bri@@ beijing newspaper stainless collection pensiunea trevi trevi lig@@ pur@@ seaside\n",
      "third asts section bremen reland kastrup above posed posed alexand@@ bakery arg@@ itality freedom bri@@ beijing newspaper stainless collection pensiunea trevi trevi lig@@ pur@@ seaside\n"
     ]
    }
   ],
   "source": [
    "dummy_translations, dummy_states = model.translate_lines(train_inp[:3], max_len=25)\n",
    "print(\"Translations without training:\")\n",
    "print('\\n'.join([line for line in dummy_translations]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wuv1-aVlrs0"
   },
   "source": [
    "### Задание 2 (2 балла)\n",
    "\n",
    "Тут нечего объяснять, нужно написать лосс, чтобы все училось:\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X, Y \\in D} \\sum_{y_t \\in Y} - \\log p(y_t \\mid y_1, \\dots, y_{t-1}, X, \\theta) $$\n",
    "\n",
    "где $|D|$ это суммарная длина всех предложений включая все токены: BOS, EOS но не включая падинг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c8XPV8sWlrs5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loss_function(model, inp, out, **flags):\n",
    "    \"\"\"\n",
    "    Функция для подсчета лосса\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "    \n",
    "    Для того чтобы пройти тесты, ваша функция должна\n",
    "    * учитывать в loss первый EOS, но НЕ учиттывать последующие\n",
    "    * разделить loss на длину вхходящей последовательности (use voc.compute_mask)\n",
    "    \"\"\"\n",
    "    mask = model.out_voc.compute_mask(out) # [batch_size, out_len]\n",
    "    targets_1hot = F.one_hot(out, len(model.out_voc)).to(torch.float32)\n",
    "    \n",
    "    # outputs of the model, [batch_size, out_len, num_tokens]\n",
    "    logits_seq = model(inp, out)\n",
    "\n",
    "    # log-probabilities всех токенов на всех шагах\n",
    "    logprobs_seq = torch.log_softmax(logits_seq, dim=-1) # [batch_size, out_len, num_tokens]\n",
    "   \n",
    "    # log-probabilities для верных ответов\n",
    "    logp_out = (logprobs_seq * targets_1hot).sum(dim=-1) # [batch_size, out_len]\n",
    "    # нужно обойтись только векторными операциями без for\n",
    "\n",
    "    # cross-entropy по всем токенам где mask == True  \n",
    "    return -logp_out[mask].mean()# тут должен получиться скаляр!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ME_LWUeklrs7",
    "outputId": "9e308b60-770f-4296-8cbe-f15fb8cffb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(7.5479, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_loss = loss_function(model, dummy_inp_tokens, dummy_out_tokens)\n",
    "print(\"Loss:\", dummy_loss)\n",
    "assert np.allclose(dummy_loss.item(), 7.5, rtol=0.1, atol=0.1)\n",
    "\n",
    "# test autograd\n",
    "dummy_loss.backward()\n",
    "for name, param in model.named_parameters():\n",
    "    assert param.grad is not None and abs(param.grad.max()) != 0, f\"Param {name} received no gradients\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1nEIXbgPnYR"
   },
   "source": [
    "### Метрика: BLEU\n",
    "\n",
    "Для оценки машинного перевода обычно используется метрика [BLEU](https://en.wikipedia.org/wiki/BLEU). Она просто считает кол-во правильно предсказанных n-grams для n=1,2,3,4 и потом берет геометрическое среднее для полученных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Gb1-PhKIlrs-"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
    "    \"\"\"\n",
    "    пример как считать метрику BLEU. Вы можете изменять вход и выход, \n",
    "    как вам удобно, главное оставьте логику ее подсчета!!!\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "        translations = [line.replace(bpe_sep, '') for line in translations]\n",
    "        actual = [line.replace(bpe_sep, '') for line in out_lines]\n",
    "        return corpus_bleu(\n",
    "            [[ref.split()] for ref in actual],\n",
    "            [trans.split() for trans in translations],\n",
    "            smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
    "            ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZvfid1RlrtA",
    "outputId": "71aea4cb-8654-4f45-ec0b-540771010ad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014860003860051633"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(model, dev_inp, dev_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQDhGwg4lrtC"
   },
   "source": [
    "### Training loop (1 балл)\n",
    "\n",
    "Нужно просто написать цикл обучения и подсчитать метрики! И пройти assert по качеству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yfwIaixHlrtI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
    "\n",
    "model = BaseModel(inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMy7MjcOr_1Y",
    "outputId": "b70a3087-90b4-4135-b59d-581dfb85c36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss: 0.1252665870385115, test_loss: 0.10390816068649292, test_bleu: 8.239405924108672\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 2\n",
      "train_loss: 0.09625247757915882, test_loss: 0.09427293046315512, test_bleu: 10.013998087589126\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 3\n",
      "train_loss: 0.08723663362055971, test_loss: 0.08977476414044698, test_bleu: 12.246843346747765\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 4\n",
      "train_loss: 0.08145729054471502, test_loss: 0.08722387997309367, test_bleu: 13.799364263583627\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 5\n",
      "train_loss: 0.07721977079577381, test_loss: 0.08584961473941803, test_bleu: 14.959072198898907\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 6\n",
      "train_loss: 0.07391759257694906, test_loss: 0.08512955085436504, test_bleu: 15.598574089847952\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 7\n",
      "train_loss: 0.07120828187880862, test_loss: 0.08482966701189677, test_bleu: 16.335519076847017\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 8\n",
      "train_loss: 0.06891000548316246, test_loss: 0.08475784810384114, test_bleu: 16.377209609271276\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 9\n",
      "train_loss: 0.06691605402422429, test_loss: 0.08489069557189942, test_bleu: 16.734325824004426\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 10\n",
      "train_loss: 0.06515382409123664, test_loss: 0.08527911146481831, test_bleu: 16.921017031863357\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 11\n",
      "train_loss: 0.06358604663123613, test_loss: 0.08581923417250316, test_bleu: 16.903843437601537\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 12\n",
      "train_loss: 0.062169865269282636, test_loss: 0.08661232304573059, test_bleu: 16.412239509901987\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 13\n",
      "train_loss: 0.060899901224200755, test_loss: 0.08699624717235566, test_bleu: 16.654903275074567\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 14\n",
      "train_loss: 0.05971142298688138, test_loss: 0.08763508637746176, test_bleu: 16.58321709194673\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 15\n",
      "train_loss: 0.05862388446791061, test_loss: 0.08836958952744801, test_bleu: 16.344594025371077\n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "\n",
    "    for i in range(0, len(train_inp), batch_size):\n",
    "\n",
    "        dummy_inp_t_tokens = inp_voc.to_matrix(train_inp[i:i+batch_size]).to(device)\n",
    "        dummy_out_t_tokens = out_voc.to_matrix(train_out[i:i+batch_size]).to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        loss = loss_function(model, dummy_inp_t_tokens, dummy_out_t_tokens)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss_epoch += loss.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        bleu = compute_bleu(model, dev_inp, dev_out)\n",
    "\n",
    "        for i in range(0, len(dev_inp), batch_size):\n",
    "            dummy_inp_d_tokens = inp_voc.to_matrix(dev_inp[i:i+batch_size]).to(device)\n",
    "            dummy_out_d_tokens = out_voc.to_matrix(dev_out[i:i+batch_size]).to(device)\n",
    "\n",
    "            loss = loss_function(model, dummy_inp_d_tokens, dummy_out_d_tokens)\n",
    "\n",
    "            test_loss_epoch += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss: {train_loss_epoch / len(train_inp)}, test_loss: {test_loss_epoch / len(dev_inp)}, test_bleu: {bleu}')\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    metrics['train_loss'].append(train_loss_epoch / len(train_inp))\n",
    "    metrics['dev_bleu'].append(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ahuhKVhlrtP",
    "outputId": "4ac5200c-df5d-43a5-b8e2-446d53c57d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU seq2seq: 16.344594025371077\n"
     ]
    }
   ],
   "source": [
    "print(f'Final BLEU seq2seq: {compute_bleu(model, dev_inp, dev_out)}')\n",
    "\n",
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0) > 15, \"Ты можешь больше! попробуй еще раз)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyaHOpealrtS",
    "outputId": "6c95f5ba-4281-4c90-8c0b-fd3be05b089f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в распоряжении гостей общая кухня и общая гостиная .\n",
      "guests can use the shared kitchen facilities and a shared kitchen .\n",
      "\n",
      "кроме того , предоставляется прокат велосипедов , услуги трансфера и бесплатная парковка .\n",
      "bicycle rental is available , and free parking is available on site .\n",
      "\n",
      "расстояние до города ки@@ сси@@ м@@ ми составляет 26 км .\n",
      "latina is 26 km from the property .\n",
      "\n",
      "апартаменты в пент@@ хаусе с общим открытым бассейном , садом , кондиционером и террасой для загара расположены в 5 минутах ходьбы от пляжа на курорте ка@@ бо - рой .\n",
      "featuring a garden with a terrace and a terrace , villa villa la is a villa with a terrace , and a terrace is located in the garden .\n",
      "\n",
      "апартаменты mo@@ s@@ co@@ w point - loft red square находятся в москве , в 200 метрах от большого театра .\n",
      "red square in the heart of rome is a 5 - minute walk from the old town square .\n",
      "\n",
      "в вашем распоряжении собственная ванная комната с душем и полотенцами .\n",
      "the private bathroom comes with a shower and towels .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp_line, trans_line in zip(dev_inp[::500], model.translate_lines(dev_inp[::500])[0]):\n",
    "    print(inp_line)\n",
    "    print(trans_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tv0s8qxOXp5y"
   },
   "source": [
    "## Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edk_oVg0lrtW"
   },
   "source": [
    "### Задание 3\n",
    "\n",
    "В этом разделе мы хотим, чтобы вы усовершенствовали базовую модель\n",
    "\n",
    "\n",
    "Сначала напишем слой Attention, а потом внедрим его в уже существующий шаблон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz9aROAIlrtX"
   },
   "source": [
    "### Attention layer (1 points)\n",
    "\n",
    "На вход подается скрытые состояния encoder $h^e_0, h^e_1, h^e_2, ..., h^e_T$ и предыдущие состояние декодера $h^d$,\n",
    "\n",
    "* Считаем логиты:\n",
    "$$a_t = linear_{out}(tanh(linear_{e}(h^e_t) + linear_{d}(h_d)))$$\n",
    "* Получаем вероятности из логитов: \n",
    "$$ p_t = {{e ^ {a_t}} \\over { \\sum_\\tau e^{a_\\tau} }} $$\n",
    "\n",
    "* Взвешиваем состояния энкодера с полученными вероятностями\n",
    "$$ attn = \\sum_t p_t \\cdot h^e_t $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BewNQx-LPnYS"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, enc_size, dec_size, hid_size):\n",
    "        super().__init__()\n",
    "        self.enc_size = enc_size \n",
    "        self.dec_size = dec_size \n",
    "        self.hid_size = hid_size \n",
    "        \n",
    "        # опишите все слои, которые нужны Attention\n",
    "        self.lin1 = nn.Linear(enc_size, hid_size)\n",
    "        self.lin2 = nn.Linear(dec_size, hid_size)\n",
    "        self.lin3 = nn.Linear(hid_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Подсчитываем attention ответ and веса\n",
    "        :param enc: [batch_size, ninp, enc_size]\n",
    "        :param dec: decode state[batch_size, dec_size]\n",
    "        :param inp_mask: маска, 0 там где pading [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "        \"\"\"\n",
    "        batch_size, ninp, enc_size = enc.shape\n",
    "\n",
    "        dec_output = self.lin2(dec)\n",
    "        dec_output = dec_output.reshape(-1, 1, self.hid_size)\n",
    "        enc_output = self.lin1(enc)\n",
    "\n",
    "        energy = torch.tanh(enc_output + dec_output)\n",
    "        energy = self.lin3(energy)\n",
    "\n",
    "        # Применим маску - если значение маски 0, логиты должны быть -inf или -1e9\n",
    "        # Лучше использовать torch.where\n",
    "        energy[torch.where(inp_mask == False)] = -1e9\n",
    "\n",
    "        # Примените softmax\n",
    "        probs = self.softmax(energy.reshape(batch_size, ninp))\n",
    "\n",
    "        # Подсчитайте выход attention используя enc состояния и вероятностями\n",
    "        attn = (probs.reshape(batch_size, ninp, 1) * enc).sum(axis=1)\n",
    "\n",
    "        return attn, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IalfpdAelrtb"
   },
   "source": [
    "### Seq2seq model with attention (2 points)\n",
    "\n",
    "Теперь вы можете использовать уровень внимания для построения сети. Самый простой способ реализовать внимание - использовать его на этапе декодирования:\n",
    "\n",
    "\n",
    "На каждом шаге используйте предыдущее состояние декодера, и написанный слой Attention\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NCKPB5JmcE6j"
   },
   "outputs": [],
   "source": [
    "class AttentiveModel(BaseModel):\n",
    "    def __init__(self, inp_voc, out_voc,\n",
    "                 emb_size=64, hid_size=128, attn_size=128):\n",
    "        \"\"\"Переводчик с Attention\"\"\"\n",
    "        super().__init__(inp_voc, out_voc, emb_size, hid_size)\n",
    "\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size \n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size + hid_size, hid_size)\n",
    "        self.attention = AttentionLayer(hid_size, hid_size, attn_size)\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Считаем скрытые скрытые состояния, которые используем в decode\n",
    "        :param inp: матрица входных токенов\n",
    "        \"\"\"\n",
    "        \n",
    "        input_emb = self.emb_inp(inp)\n",
    "\n",
    "        # делаем encode\n",
    "        enc_seq, _ = self.enc0(input_emb)\n",
    "\n",
    "        [dec_start] = super().encode(inp, **flags)    \n",
    "        \n",
    "        enc_mask = self.out_voc.compute_mask(inp)\n",
    "        \n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        # применяем attention слой для скрытых состояний\n",
    "        first_attn_probas = self.attention(enc_seq, dec_start, enc_mask)[1]\n",
    "        \n",
    "        # Для декодера нужно вернуть:\n",
    "        # - начальное состояние для RNN декодера\n",
    "        # - последовательность скрытых состояний encoder, maskа для них\n",
    "        # - последним передаем вероятности слоя attention\n",
    "        \n",
    "        first_state = [dec_start, enc_seq, enc_mask, first_attn_probas]\n",
    "\n",
    "        return first_state\n",
    "   \n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Принимает предыдущее состояние декодера и токены, возвращает новое состояние и логиты для следующих токенов\n",
    "        :param prev_state: список тензоров предыдущих состояний декодера\n",
    "        :param prev_tokens: предыдущие выходные токены [batch_size]\n",
    "        :return: список тензоров состояния следующего декодера, тензор логитов [batch, n_tokens]\n",
    "        \"\"\"\n",
    "        \n",
    "        prev_gru0_state, enc_seq, enc_mask, _ = prev_state\n",
    "        attn, attn_prob = self.attention(enc_seq, prev_gru0_state, enc_mask)\n",
    "        \n",
    "        x = self.emb_out(prev_tokens)\n",
    "        \n",
    "        x = torch.cat([attn, x], dim=-1)\n",
    "        x = self.dec0(x, prev_gru0_state)\n",
    "        \n",
    "        new_dec_state = [x, enc_seq, enc_mask, attn_prob]\n",
    "        output_logits = self.logits(x)\n",
    "\n",
    "        return [new_dec_state, output_logits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryZCOTEslrtf"
   },
   "source": [
    "### Обучение модели (1 points)\n",
    "\n",
    "Нужно обучить AttentiveModel и пройти assert по качеству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-YMHPgZxcFaQ"
   },
   "outputs": [],
   "source": [
    "metrics_attention = {'train_loss': [], 'dev_bleu': [] }\n",
    "\n",
    "model_attention = AttentiveModel(inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.AdamW(model_attention.parameters(), lr=3e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=1, factor=0.7)\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kv96dpAMPnYS",
    "outputId": "d467394d-d0de-4cb7-ad17-cd9825166b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss: 0.1126214658470119, test_loss: 0.09245521680514018, test_bleu: 11.502508159520703, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 2\n",
      "train_loss: 0.08417063795889451, test_loss: 0.08443691802024841, test_bleu: 18.209390616177835, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 3\n",
      "train_loss: 0.07429351820793256, test_loss: 0.08137622551123301, test_bleu: 19.250274181288354, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 4\n",
      "train_loss: 0.06804964365404932, test_loss: 0.08012110948562622, test_bleu: 20.387146282763418, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 5\n",
      "train_loss: 0.06347245269753964, test_loss: 0.07954873319466908, test_bleu: 21.7451805650297, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 6\n",
      "train_loss: 0.059916555755952706, test_loss: 0.07950067762533823, test_bleu: 21.58654145990302, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 7\n",
      "train_loss: 0.056962275532458105, test_loss: 0.08028796267509461, test_bleu: 21.500096674316573, lr: 0.003\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 8\n",
      "train_loss: 0.05444665854871152, test_loss: 0.08025012358029683, test_bleu: 22.440887560366313, lr: 0.0021\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 9\n",
      "train_loss: 0.049822958714733585, test_loss: 0.07988262915611268, test_bleu: 22.85556931899763, lr: 0.0021\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 10\n",
      "train_loss: 0.04749870669580272, test_loss: 0.08077151004473368, test_bleu: 22.278309801193085, lr: 0.0014699999999999997\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 11\n",
      "train_loss: 0.044296366306434874, test_loss: 0.08066701757907867, test_bleu: 23.160628921678423, lr: 0.0014699999999999997\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 12\n",
      "train_loss: 0.04257623700420313, test_loss: 0.08173725334803264, test_bleu: 22.655275984924057, lr: 0.0010289999999999997\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 13\n",
      "train_loss: 0.0403353297957202, test_loss: 0.08189018734296163, test_bleu: 22.64397917208186, lr: 0.0010289999999999997\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 14\n",
      "train_loss: 0.03893063171922226, test_loss: 0.08229818777243296, test_bleu: 22.857616661400737, lr: 0.0007202999999999998\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 15\n",
      "train_loss: 0.03720468947847905, test_loss: 0.0825413212776184, test_bleu: 23.707036766671393, lr: 0.0007202999999999998\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 16\n",
      "train_loss: 0.036203979000162895, test_loss: 0.08325962448120117, test_bleu: 23.80425199834086, lr: 0.0005042099999999998\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 17\n",
      "train_loss: 0.035043126680615565, test_loss: 0.08349152187506358, test_bleu: 23.649799300273212, lr: 0.0005042099999999998\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 18\n",
      "train_loss: 0.03424957179457088, test_loss: 0.0840808275938034, test_bleu: 23.432479084956366, lr: 0.0003529469999999999\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 19\n",
      "train_loss: 0.03336088487851929, test_loss: 0.08438120369116466, test_bleu: 23.78142638177585, lr: 0.0003529469999999999\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Epoch 20\n",
      "train_loss: 0.03275827212332766, test_loss: 0.0848504231373469, test_bleu: 23.588169509974072, lr: 0.0002470628999999999\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    model_attention.train()\n",
    "\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "\n",
    "    for i in range(0, len(train_inp), batch_size):\n",
    "\n",
    "        dummy_inp_t_tokens = inp_voc.to_matrix(train_inp[i:i+batch_size]).to(device)\n",
    "        dummy_out_t_tokens = out_voc.to_matrix(train_out[i:i+batch_size]).to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        loss = loss_function(model_attention, dummy_inp_t_tokens, dummy_out_t_tokens)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss_epoch += loss.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model_attention.eval()\n",
    "\n",
    "        bleu = compute_bleu(model_attention, dev_inp, dev_out)\n",
    "\n",
    "        for i in range(0, len(dev_inp), batch_size):\n",
    "            dummy_inp_d_tokens = inp_voc.to_matrix(dev_inp[i:i+batch_size]).to(device)\n",
    "            dummy_out_d_tokens = out_voc.to_matrix(dev_out[i:i+batch_size]).to(device)\n",
    "\n",
    "            loss = loss_function(model_attention, dummy_inp_d_tokens, dummy_out_d_tokens)\n",
    "\n",
    "            test_loss_epoch += loss.item()\n",
    "\n",
    "    scheduler.step(test_loss_epoch / len(dev_inp))\n",
    "\n",
    "    curr_lr = opt.param_groups[0]['lr']\n",
    "\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss: {train_loss_epoch / len(train_inp)}, test_loss: {test_loss_epoch / len(dev_inp)}, test_bleu: {bleu}, lr: {curr_lr}')\n",
    "    print('--------------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    metrics_attention['train_loss'].append(train_loss_epoch / len(train_inp))\n",
    "    metrics_attention['dev_bleu'].append(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_kS_0mjPnYS",
    "outputId": "e379505c-52fb-40d9-e5f1-18275c64af6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU seq2seq with attention: 23.588169509974072\n"
     ]
    }
   ],
   "source": [
    "print(f'Final BLEU seq2seq with attention: {compute_bleu(model_attention, dev_inp, dev_out)}')\n",
    "    \n",
    "assert np.mean(metrics_attention['dev_bleu'][-10:], axis=0) > 23, \"Ты можешь больше! попробуй еще раз)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6_YzrRwPnYS",
    "outputId": "e0f54182-3a4c-4387-9296-a532694bb04c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в распоряжении гостей общая кухня и общая гостиная .\n",
      "you will find a shared kitchen and a shared lounge at the property .\n",
      "\n",
      "кроме того , предоставляется прокат велосипедов , услуги трансфера и бесплатная парковка .\n",
      "bicycle rental , bicycle rental and shuttle service can be arranged .\n",
      "\n",
      "расстояние до города ки@@ сси@@ м@@ ми составляет 26 км .\n",
      "kissimmee is 26 km from the property .\n",
      "\n",
      "апартаменты в пент@@ хаусе с общим открытым бассейном , садом , кондиционером и террасой для загара расположены в 5 минутах ходьбы от пляжа на курорте ка@@ бо - рой .\n",
      "featuring a wellness area , garden and terrace , sun terrace offers a sun terrace and a terrace . the beach is a 5 - minute walk from the beach of mon@@ tre@@ y@@ era .\n",
      "\n",
      "апартаменты mo@@ s@@ co@@ w point - loft red square находятся в москве , в 200 метрах от большого театра .\n",
      "ev@@ sky mosque is 200 metres from the house .\n",
      "\n",
      "в вашем распоряжении собственная ванная комната с душем и полотенцами .\n",
      "featuring a shower , private bathrooms also come with towels .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp_line, trans_line in zip(dev_inp[::500], model_attention.translate_lines(dev_inp[::500])[0]):\n",
    "    print(inp_line)\n",
    "    print(trans_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRBmn4pWPnYS"
   },
   "source": [
    "## Как решать NLP задачу? Дообучить модель из huggingface\n",
    "\n",
    "Как мы видели на последнем семинаре в прошлом модуле можно получить отлично качество генерации текста, написав при этом не очень много строк кода, может быть попробовать тут также?)\n",
    "\n",
    "Это отличная идея!\n",
    "\n",
    "### Задание 4 (2 points)\n",
    " \n",
    "Нужно взять модель из [huggingface](https://huggingface.co/models?pipeline_tag=translation&sort=downloads), дообучить на наших данных и посмотреть, какое качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ammR_DsPYiE"
   },
   "source": [
    "Так как у предобученных сеток есть свои токенизаторы, я возьму наши сырые данные и буду их подавать в модель из HF, без нашего BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMKC7RAXTr1h"
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers==4.28.1 sentencepiece==0.1.94 sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YWL6dVCTkXd"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_metric \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2j0PUrPfPpAK"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/data.txt') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkIVDbj3Ov6w"
   },
   "source": [
    "### Статистика длин текстов в корпусе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrmVWWYPPkfu"
   },
   "source": [
    "Длина здесь считается грубо, потому что идет сплит по пробелам, никак не учитываются знаки препинания, но для оценки такой способ подойдет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VHwGPZRNO134"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_texts_ru = []\n",
    "all_texts_en = []\n",
    "\n",
    "for d in data:\n",
    "    all_texts_ru.append(len(d.split('\\t')[1][:-1].split()))\n",
    "    all_texts_en.append(len(d.split('\\t')[0].split()))\n",
    "\n",
    "df_len_texts_ru = pd.DataFrame(data=all_texts_ru, columns=['len_texts'])\n",
    "df_len_texts_en = pd.DataFrame(data=all_texts_en, columns=['len_texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "2zDXNM8_O6qz",
    "outputId": "28702a45-6103-4b6b-ed3a-5fa391fbfc3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b5612f49-dd01-4d90-91da-c048d4a088cf\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.469060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.694053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5612f49-dd01-4d90-91da-c048d4a088cf')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b5612f49-dd01-4d90-91da-c048d4a088cf button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b5612f49-dd01-4d90-91da-c048d4a088cf');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          len_texts\n",
       "count  50000.000000\n",
       "mean      13.469060\n",
       "std        6.694053\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%       12.000000\n",
       "75%       17.000000\n",
       "max       63.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len_texts_ru.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "B52IiTn7O9uT",
    "outputId": "eb540ec6-cbdb-45f8-cf08-f255283d5830"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_len_texts_ru.hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "dhUlZ4LkO9zG",
    "outputId": "31748fbc-7047-4232-88d1-94c593133c77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8879e816-0de9-4614-9dc2-73ced2b2e460\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.198160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.693823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8879e816-0de9-4614-9dc2-73ced2b2e460')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8879e816-0de9-4614-9dc2-73ced2b2e460 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8879e816-0de9-4614-9dc2-73ced2b2e460');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          len_texts\n",
       "count  50000.000000\n",
       "mean      14.198160\n",
       "std        6.693823\n",
       "min        1.000000\n",
       "25%        9.000000\n",
       "50%       13.000000\n",
       "75%       18.000000\n",
       "max       83.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len_texts_en.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "v6yNtaPvPDxF",
    "outputId": "1ac996a6-24da-407b-d33e-506b4f7e901f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_len_texts_en.hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phKZcZ55QHj0"
   },
   "source": [
    "**Вывод**: если посмотреть на распредления длин русских и английских текстов можно заметить, что хорошим параметром максимальной длины в токенизаторе будет в районе 20-30, последовательности больше данной длины будем обрезать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GGQEWREQ6jX"
   },
   "source": [
    "### Подготовка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "cCVFCTSvUUAt"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=3000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IZAfxsCUSUJj"
   },
   "outputs": [],
   "source": [
    "def create_dict_data(data):\n",
    "    dict_data = {}\n",
    "    dict_data['translation'] = []\n",
    "    \n",
    "    for d in data:\n",
    "        dict_data['translation'].append({'ru': d.split('\\t')[1][:-1], 'en': d.split('\\t')[0]})\n",
    "\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "AmkLzEroTGCU"
   },
   "outputs": [],
   "source": [
    "train_data_prep = Dataset.from_dict(create_dict_data(train_data))\n",
    "test_data_prep = Dataset.from_dict(create_dict_data(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "odhvymXxT2ZG"
   },
   "outputs": [],
   "source": [
    "data_prep = DatasetDict({\"train\": train_data_prep, \"test\": test_data_prep})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "188_kHvLX_CW"
   },
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2pG5yHlPnYS"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\", use_fast=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "FaYDlJfBRY5A"
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "batch_size = 32\n",
    "learning_rate = 2e-5\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkxNMDN0SNhx"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"ru\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = data_prep.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "3JGniBDSW_nS"
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Без этого препроцессинга я сутки не мог посчитать метрику из-за CUDA ot of memory...\n",
    "    Спасибо человеку с обсуждения ниже!!!!\n",
    "    https://discuss.huggingface.co/t/cuda-out-of-memory-when-using-trainer-with-compute-metrics/2941/12\n",
    "    \"\"\"\n",
    "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
    "    \n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "gvDDaDQnSNzd"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "WbGrbJrgWz-h"
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(output_dir='/content/drive/MyDrive/tmp/',\n",
    "                                  num_train_epochs=epochs,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Lm2YcxLiSN2S"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics # must have для моего случая\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "IJ4q79GUXFLc",
    "outputId": "902fd902-da4e-4e98-850f-c75477337716"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7345' max='7345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7345/7345 20:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.310200</td>\n",
       "      <td>1.949208</td>\n",
       "      <td>28.717400</td>\n",
       "      <td>19.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.921000</td>\n",
       "      <td>1.753640</td>\n",
       "      <td>30.051800</td>\n",
       "      <td>19.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.762400</td>\n",
       "      <td>1.673494</td>\n",
       "      <td>29.371800</td>\n",
       "      <td>19.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.625700</td>\n",
       "      <td>1.628074</td>\n",
       "      <td>30.072100</td>\n",
       "      <td>19.999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.597100</td>\n",
       "      <td>1.593474</td>\n",
       "      <td>30.601500</td>\n",
       "      <td>19.999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.564500</td>\n",
       "      <td>1.569674</td>\n",
       "      <td>31.044300</td>\n",
       "      <td>19.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.486600</td>\n",
       "      <td>1.554441</td>\n",
       "      <td>31.126900</td>\n",
       "      <td>19.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.474600</td>\n",
       "      <td>1.539708</td>\n",
       "      <td>31.365700</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.448300</td>\n",
       "      <td>1.532679</td>\n",
       "      <td>31.558700</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.410900</td>\n",
       "      <td>1.523284</td>\n",
       "      <td>31.687100</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.415500</td>\n",
       "      <td>1.513052</td>\n",
       "      <td>31.588700</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.382200</td>\n",
       "      <td>1.511030</td>\n",
       "      <td>31.877300</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.378000</td>\n",
       "      <td>1.507688</td>\n",
       "      <td>31.954500</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.361100</td>\n",
       "      <td>1.504480</td>\n",
       "      <td>31.913300</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "FJfIEZckPnYS",
    "outputId": "f18d9b9e-ac08-42fc-d7eb-52de51758415"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [94/94 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU seq2seq HF: 31.8692\n"
     ]
    }
   ],
   "source": [
    "print(f'Final BLEU seq2seq HF: {trainer.evaluate()[\"eval_bleu\"]}')\n",
    "\n",
    "# руками пропишу 10 последних значение bleu из логгирования трейнера, нагуглить как у него вытащить именно метрику, а не лосс быстро не получилось\n",
    "metrics_hf = {}\n",
    "metrics_hf['dev_bleu'] = [30.601500, 31.044300, 31.126900, 31.365700, 31.558700, 31.687100, 31.588700, 31.877300, 31.954500, 31.913300]\n",
    "\n",
    "assert np.mean(metrics_hf['dev_bleu'][-10:], axis=0) > 27, \"Ты можешь больше! попробуй еще раз)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnU2OwRUgH1y"
   },
   "source": [
    "## Вывод\n",
    "Финальные метрики BLEU у всех трех подходов:\n",
    "\n",
    "**seq2seq** - 16.34\n",
    "\n",
    "**seq2seq with attention** - 23.59\n",
    "\n",
    "**fine-tuning HF model** - 31.87"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "edk_oVg0lrtW"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
